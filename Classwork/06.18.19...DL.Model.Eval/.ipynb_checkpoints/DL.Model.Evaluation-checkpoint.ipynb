{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§î Deep Learning Model Evaluation ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in....\n",
    "* plotting **training accuracy** and **testing accuracy** over epochs\n",
    "* seeing that **loss decreases** over epochs\n",
    "\n",
    "***Plotting Accuracy over Epochs***\n",
    "```python\n",
    "#passing in all data - validation_split will divide it. Without validation_split, pass in training data\n",
    "history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
    "print(history.history.keys()) #list all data in history\n",
    "plt.plot(history.history['acc']) #summarize history for accuracy\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Plotting Loss over Epochs**\n",
    "```python\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìû Callbacks in Keras\n",
    "\n",
    "* **Callbacks**: functions that can be applied at certain stages of the training process, such as at the end of each epoch\n",
    "* Specifically, in our solution, we included ```EarlyStopping(monitor='val_loss', patience=2)``` to define that we wanted to monitor the validation loss @ each epoch.\n",
    "    * If validation loss *fails to improve* after *2 epochs*, training is interrupted\n",
    "* Since we set ```patience=2```, we won't get the best model, but the model 2 epochs after the best model.\n",
    "    * Thus, we can (optionally) include a second operation, ```ModelCheckpoint```, which saves the model to a file after every checkpoint\n",
    "    \n",
    "```python\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "```\n",
    "\n",
    "Then,\n",
    "\n",
    "```python\n",
    "# Train neural network\n",
    "history = model.fit(train_features, # Features\n",
    "                train_target, # Target vector\n",
    "                epochs=20, # Number of epochs\n",
    "                callbacks=callbacks, # Early stopping\n",
    "                verbose=0, # Print description after each epoch\n",
    "                batch_size=100, # Number of observations per batch\n",
    "                validation_data=(test_features, test_target)) # Data for evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üò± Tensorboard\n",
    "\n",
    "* Hosts a website on your local machine in which you can monitor things like accuracy, cost functions and visualize the computational graph that Tensorflow is running baesd on what you defined in Keras\n",
    "* For monitoring progress, open the terminal: ```tensorboard --logdir Graph```\n",
    "\n",
    "‚ùóÔ∏èUse the following in the MNIST hw:\n",
    "\n",
    "```python\n",
    "from keras.callbacks import TensorBoard\n",
    "tensor_board = TensorBoard(log_dir='./Graph')\n",
    "model.fit(x_train, y_train, verbose=1, callbacks=[tensor_board])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2207 - acc: 0.9310 - val_loss: 0.1017 - val_acc: 0.9686\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0822 - acc: 0.9749 - val_loss: 0.0841 - val_acc: 0.9750\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0542 - acc: 0.9827 - val_loss: 0.0708 - val_acc: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c419b09e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 3\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "tensor_board = keras.callbacks.TensorBoard(\"logs\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [tensor_board],\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úùÔ∏è Save and Load Keras Model\n",
    "\n",
    "Given that DL models can take a *long* time to train, it's important to know how to save & load them from disk.\n",
    "\n",
    "Options:\n",
    "1. Weights & Model Architecture\n",
    "1. Save/Load the Entire Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice 1: Save weights & architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#save weights and architecture\n",
    "model.save_weights('model_weights.h5')\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "    \n",
    "#load weights and architecture\n",
    "with open('model_architecture.json', 'r') as f:\n",
    "    new_model_1 = model_from_json(f.read())\n",
    "new_model_1.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice 2: Save/load the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5') #creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "del model #deletes the existing model\n",
    "\n",
    "model = load_model('my_model.h5') #returns a compiled model identical to the previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚¨áÔ∏è Scalable Vector Graphics (SVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unrelated, I think. This is the syntax that would show a dataframe with the weights.\n",
    "\n",
    "```python\n",
    "variable_name = model.get_layer(name='layer_name_i_think').get_weights()[0]\n",
    "pd.DataFrame(variable_name).describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
