{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§î Deep Learning Glossary ü§î\n",
    "\n",
    "**Deep Learning** (DL) components & technologies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí• Activation Function\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=x.shape[1]))\n",
    "```\n",
    "\n",
    "* Allows NNs to learn complex **decision boundaries**\n",
    "* We apply a **nonlinear activation function** to some of its layers\n",
    "* Commonly used functions include:\n",
    "    * softmax\n",
    "    * **sigmoid**\n",
    "    * tanh\n",
    "    * ReLU (*Rectified Linear Unit*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíî Loss Function (Cost Function)\n",
    "\n",
    "* NN will try to predict the output as close as possible to the actual value\n",
    "* For **prediction** problems, the cost functions are:\n",
    "    * MSE, MAE, ...\n",
    "    * ```model.compile(optimizer='rmsprop', loss='mse')```\n",
    "* For **classification** problems, the cost functions are:\n",
    "    * Categorical Cross-Entropy, Binary Cross-Entropy\n",
    "    * ```model.compile(optimizer='rmsprop', loss='binary_crossentropy')```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Algorithms (or Optimization Methods) to Minimize Error\n",
    "\n",
    "* **Gradient Descent** (*GD*)\n",
    "    * While climbing down a hill, you should take small steps and walk down instead of just jumping down all at once.\n",
    "    * Thus, if we start from point *x*, we move down a little (i.e. *delta h*) and update our position to x-delta h.\n",
    "    * We keep doing that until we reach the bottom.\n",
    "* **Stochastic Gradient Descent** (*SGD*)\n",
    "* ***Learning rate***: Both GD & SGD need learning rate to adjust the new weight\n",
    "    * w1_new = w1 + (learning rate) * (derivative of cost function wrt w1)\n",
    "    * RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚¨áÔ∏è Dropout\n",
    "\n",
    "* A regularization technique for NNs that prevents **overfitting**\n",
    "* ```model.add(Dropout(0.25))```\n",
    "\n",
    "<img src=\"dropout.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Epoch and Batch\n",
    "\n",
    "* **Epoch**: When an ENTIRE dataset is passed forward and backward (i.e. propagates forward and backward) through the NN\n",
    "    * ```model.fit(x, y, epochs=10, validation_data=(x_val, y_val))```\n",
    "* **Batch**: Number of samples per gradient update\n",
    "    * ```model.fit(x, y, batch_size=2, epochs=10)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìäBatch Normalization\n",
    "\n",
    "* A technique that normalizes the data even at hidden layers\n",
    "* ```model.add(BatchNormalization())```\n",
    "\n",
    "<img src=\"batch_normalization.png\" width=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíö Activity: Apply NN with Keras on iris data\n",
    "\n",
    "* Use 100 samples for training & 50 samples for validation.\n",
    "* Set the value of epoch to 5.\n",
    "* Change the ```batch_size``` value from 1 to 100 and plot the accuracy versus batch_size\n",
    "* Change the ```verbose``` to 0, 1, and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíö Activity: Apply Lambda Layer in Keras and test how it works.\n",
    "\n",
    "* Write code that takes an array with size 3 and apply a Lambda Layer in Keras to double the array's elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/cherishkim/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10. 24.  2.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cherishkim/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Input\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input = Input(shape=(3,))\n",
    "double = Lambda(lambda x: 2 * x)(input)\n",
    "\n",
    "model = Model(input=input, output=double)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "data=np.array([[5, 12, 1]])\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
